manager:
  #Refresher's thread pool size, it's better to set it greater than NUM_OF_CRAWLER * 10
  refresher_threads: 100
  clearer_threads: 5

beggar:
  crawl_gap_time: 10
  clean_gap_time: 10

storage:
  path: "redis://127.0.0.1:6379/1"
  key: "proxy_crawler"

client:
  target: "https://www.baidu.com"
  #Global time for waiting response
  time_limit: 8
  user_agent: 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36'

crawlers:
  SevenyipCrawler:
    page_limit: 10
    time_limit: 5
  Ip3366Crawler:
    page_limit: 10